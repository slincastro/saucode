{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55660441",
   "metadata": {},
   "source": [
    "# Saucode Retrieval Evaluation Notebook\n",
    "\n",
    "Este notebook implementa la **opción completa (ideal)** para evaluar el retrieval:\n",
    "\n",
    "1. Define una lista de consultas de evaluación (`EVAL_QUERIES`).\n",
    "2. Usa el mismo Qdrant y TF–IDF del API para obtener los **top‑k** documentos.\n",
    "3. Genera un archivo `evals/retrieval_results.csv` **sin** `is_relevant`.\n",
    "4. Se anota manualmente la relevancia (`is_relevant` = 0/1).\n",
    "5. Ayuda a este notebook y para calcular **Precision@5** y **nDCG@5** para cada retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18a87789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "try:\n",
    "    from qdrant_client import QdrantClient\n",
    "    from qdrant_client.models import SparseVector\n",
    "except ImportError:\n",
    "    QdrantClient = None\n",
    "    SparseVector = None\n",
    "    print(\"[WARN] qdrant-client no está instalado en este entorno.\\n\"\n",
    "          \"Instala con: pip install qdrant-client\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5870970c",
   "metadata": {},
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cabbc7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuración de Qdrant ===\n",
    "QDRANT_URL = \"http://localhost:6333\" \n",
    "QDRANT_API_KEY = None  \n",
    "QDRANT_COLLECTION = \"code_knowledge\"  \n",
    "# === Parámetros del benchmark ===\n",
    "TOP_K = 5\n",
    "\n",
    "EVALS_DIR = \"retriever_result\"\n",
    "RETRIEVAL_RESULTS_CSV = os.path.join(EVALS_DIR, \"retrieval_results.csv\")\n",
    "TFIDF_VECTORIZER_PATH=\"../infra/vectorizer.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3ca6c",
   "metadata": {},
   "source": [
    "## Definición de consultas de evaluación (`EVAL_QUERIES`)\n",
    "\n",
    "- `query_id` es un identificador corto.\n",
    "- `query_text` es la descripción de la necesidad de información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1294e7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EVAL_QUERIES = [\n",
    "    {\"query_id\": \"q001\", \"query_text\": \"long method with many if statements in Python\"},\n",
    "    {\"query_id\": \"q002\", \"query_text\": \"refactoring guidelines for high cyclomatic complexity\"},\n",
    "    {\"query_id\": \"q003\", \"query_text\": \"clean code practices for data preprocessing pipelines\"},\n",
    "    {\"query_id\": \"q004\", \"query_text\": \"code smell: long parameter list in service functions\"},\n",
    "    {\"query_id\": \"q005\", \"query_text\": \"best practices to reduce nested loops and branches\"},\n",
    "    {\"query_id\": \"q006\", \"query_text\": \"how to refactor duplicated code across multiple modules\"},\n",
    "    {\"query_id\": \"q007\", \"query_text\": \"improving readability in deeply nested try except blocks\"},\n",
    "    {\"query_id\": \"q008\", \"query_text\": \"patterns to simplify large python classes with too many responsibilities\"},\n",
    "    {\"query_id\": \"q009\", \"query_text\": \"refactoring strategy for functions doing IO and business logic together\"},\n",
    "    {\"query_id\": \"q010\", \"query_text\": \"how to remove tight coupling between components in python applications\"},\n",
    "    {\"query_id\": \"q011\", \"query_text\": \"best practices for organizing utility functions in python projects\"},\n",
    "    {\"query_id\": \"q012\", \"query_text\": \"refactor excessive boolean flags in function signatures\"},\n",
    "    {\"query_id\": \"q013\", \"query_text\": \"replace long switch or if chains with polymorphism patterns\"},\n",
    "    {\"query_id\": \"q014\", \"query_text\": \"identify and eliminate dead code in python codebases\"},\n",
    "    {\"query_id\": \"q015\", \"query_text\": \"refactoring large dictionary-driven functions with complex rules\"},\n",
    "    {\"query_id\": \"q016\", \"query_text\": \"testing strategy for functions with side effects and global state\"},\n",
    "    {\"query_id\": \"q017\", \"query_text\": \"refactor large data transformation functions into smaller steps\"},\n",
    "    {\"query_id\": \"q018\", \"query_text\": \"design patterns to improve extensibility in ETL pipelines\"},\n",
    "    {\"query_id\": \"q019\", \"query_text\": \"how to reduce dependency on global variables in python scripts\"},\n",
    "    {\"query_id\": \"q020\", \"query_text\": \"refactoring methods that perform validation, transformation, and storage\"},\n",
    "    {\"query_id\": \"q021\", \"query_text\": \"clean architecture guidelines for python backend services\"},\n",
    "    {\"query_id\": \"q022\", \"query_text\": \"refactoring monolithic functions into command-query separation\"},\n",
    "    {\"query_id\": \"q023\", \"query_text\": \"how to restructure code to improve unit test coverage\"},\n",
    "    {\"query_id\": \"q024\", \"query_text\": \"strategies for eliminating temporal coupling in workflows\"},\n",
    "    {\"query_id\": \"q025\", \"query_text\": \"refactoring python scripts to improve maintainability and modularity\"},\n",
    "    {\"query_id\": \"q026\", \"query_text\": \"techniques to simplify callback-heavy asynchronous code\"},\n",
    "    {\"query_id\": \"q027\", \"query_text\": \"how to handle magic numbers and inline configuration values\"},\n",
    "    {\"query_id\": \"q028\", \"query_text\": \"refactor python functions that mix computation and logging\"},\n",
    "    {\"query_id\": \"q029\", \"query_text\": \"best practices to break down god classes into cohesive components\"},\n",
    "    {\"query_id\": \"q030\", \"query_text\": \"refactor long list comprehensions into readable steps\"}\n",
    "]\n",
    "\n",
    "len(EVAL_QUERIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e7cd4",
   "metadata": {},
   "source": [
    "## Función de encoding TF–IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db0ff76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "_vectorizer=None\n",
    "\n",
    "with open(TFIDF_VECTORIZER_PATH, \"rb\") as f:\n",
    "     _vectorizer = pickle.load(f)\n",
    "\n",
    "def encode_query_to_sparse_vector(text: str):\n",
    "    vec = _vectorizer.transform([text])\n",
    "    coo = vec.tocoo()\n",
    "    return coo.col.tolist(), coo.data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f239e1f",
   "metadata": {},
   "source": [
    "## Cliente de Qdrant\n",
    "\n",
    "Función auxiliar para crear el cliente de Qdrant usando la configuración anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46cfc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_qdrant_client() -> QdrantClient:\n",
    "    if QdrantClient is None:\n",
    "        raise ImportError(\n",
    "            \"qdrant-client no está disponible. Instala con: pip install qdrant-client\"\n",
    "        )\n",
    "    return QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adbb13d",
   "metadata": {},
   "source": [
    "## Función de retrieval desde Qdrant\n",
    "\n",
    "Esta función hace una búsqueda `TOP_K` usando **sparse vectors**. Si también\n",
    "quieres probar un retriever denso, puedes añadir otro bloque similar usando\n",
    "un campo de vectores densos en tu colección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6dff7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.models import NamedSparseVector, SparseVector\n",
    "\n",
    "VECTOR_NAME = \"text\"   \n",
    "\n",
    "def retrieve_top_k_sparse(client, query_text: str, top_k: int = 5):\n",
    "    indices, values = encode_query_to_sparse_vector(query_text)\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=QDRANT_COLLECTION,\n",
    "        query_vector=NamedSparseVector(\n",
    "            name=VECTOR_NAME,\n",
    "            vector=SparseVector(\n",
    "                indices=indices,\n",
    "                values=values\n",
    "            )\n",
    "        ),\n",
    "        limit=top_k,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        rows.append({\n",
    "            \"chunk_id\": r.payload.get(\"chunk_id\", r.id),\n",
    "            \"score\": r.score,\n",
    "            \"payload\": r.payload\n",
    "        })\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5ccf52",
   "metadata": {},
   "source": [
    "## Generación de `retrieval_results.csv`\n",
    "\n",
    "Este paso:\n",
    "\n",
    "1. Recorre todas las `EVAL_QUERIES`.\n",
    "2. Para cada consulta, llama al retriever **sparse** (y luego puedes añadir el denso).\n",
    "3. Construye un `DataFrame` con columnas:\n",
    "   - `query_id`, `query_text`\n",
    "   - `retriever` (por ahora: `sparse`)\n",
    "   - `rank` (1..TOP_K)\n",
    "   - `chunk_id`, `score`\n",
    "   - `is_relevant` (inicialmente `None`)\n",
    "4. Escribe el archivo en `evals/retrieval_results.csv`.\n",
    "\n",
    "Después de este paso, abre el CSV con tu editor y marca `is_relevant` con 0/1\n",
    "para cada fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5fade14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_retrieval_results_dataframe() -> pd.DataFrame:\n",
    "    client = build_qdrant_client()\n",
    "    rows = []\n",
    "\n",
    "    for q in EVAL_QUERIES:\n",
    "        qid = q[\"query_id\"]\n",
    "        qtext = q[\"query_text\"]\n",
    "\n",
    "        # --- Sparse retriever ---\n",
    "        sparse_results = retrieve_top_k_sparse(client, qtext, top_k=TOP_K)\n",
    "\n",
    "        for rank, item in enumerate(sparse_results, start=1):\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"query_id\": qid,\n",
    "                    \"query_text\": qtext,\n",
    "                    \"retriever\": \"sparse\",\n",
    "                    \"rank\": rank,\n",
    "                    \"chunk_id\": item[\"chunk_id\"],\n",
    "                    \"text\": item[\"payload\"].get(\"text\", \"\"),\n",
    "                    \"score\": item[\"score\"],\n",
    "                    \"is_relevant\": None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85494f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mt/ynd178zj0lsf9_dhk8rpqy200000gn/T/ipykernel_97202/107025455.py:8: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "      <th>retriever</th>\n",
       "      <th>rank</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>is_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>q001</td>\n",
       "      <td>long method with many if statements in Python</td>\n",
       "      <td>sparse</td>\n",
       "      <td>1</td>\n",
       "      <td>Fluent.Python.2nd.Edition.(z-lib.org).pdf:p928_c1</td>\n",
       "      <td>EAFP Easier to ask for forgiveness than permis...</td>\n",
       "      <td>0.091903</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>q001</td>\n",
       "      <td>long method with many if statements in Python</td>\n",
       "      <td>sparse</td>\n",
       "      <td>2</td>\n",
       "      <td>cc_knowledge_book.pdf:p141_c2</td>\n",
       "      <td>problems upon our callers. All it takes is one...</td>\n",
       "      <td>0.073481</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q001</td>\n",
       "      <td>long method with many if statements in Python</td>\n",
       "      <td>sparse</td>\n",
       "      <td>3</td>\n",
       "      <td>Fluent.Python.2nd.Edition.(z-lib.org).pdf:p950_c1</td>\n",
       "      <td>Chapter Summary This chapter started easily en...</td>\n",
       "      <td>0.063037</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q001</td>\n",
       "      <td>long method with many if statements in Python</td>\n",
       "      <td>sparse</td>\n",
       "      <td>4</td>\n",
       "      <td>cc_knowledge_book.pdf:p293_c1</td>\n",
       "      <td>262 Chapter 15: JUnit Internals We replaced th...</td>\n",
       "      <td>0.062122</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>q001</td>\n",
       "      <td>long method with many if statements in Python</td>\n",
       "      <td>sparse</td>\n",
       "      <td>5</td>\n",
       "      <td>Fluent.Python.2nd.Edition.(z-lib.org).pdf:p924_c1</td>\n",
       "      <td>Chapter 18. Context Managers and else Blocks A...</td>\n",
       "      <td>0.060011</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id                                     query_text retriever  rank  \\\n",
       "0     q001  long method with many if statements in Python    sparse     1   \n",
       "1     q001  long method with many if statements in Python    sparse     2   \n",
       "2     q001  long method with many if statements in Python    sparse     3   \n",
       "3     q001  long method with many if statements in Python    sparse     4   \n",
       "4     q001  long method with many if statements in Python    sparse     5   \n",
       "\n",
       "                                            chunk_id  \\\n",
       "0  Fluent.Python.2nd.Edition.(z-lib.org).pdf:p928_c1   \n",
       "1                      cc_knowledge_book.pdf:p141_c2   \n",
       "2  Fluent.Python.2nd.Edition.(z-lib.org).pdf:p950_c1   \n",
       "3                      cc_knowledge_book.pdf:p293_c1   \n",
       "4  Fluent.Python.2nd.Edition.(z-lib.org).pdf:p924_c1   \n",
       "\n",
       "                                                text     score is_relevant  \n",
       "0  EAFP Easier to ask for forgiveness than permis...  0.091903        None  \n",
       "1  problems upon our callers. All it takes is one...  0.073481        None  \n",
       "2  Chapter Summary This chapter started easily en...  0.063037        None  \n",
       "3  262 Chapter 15: JUnit Internals We replaced th...  0.062122        None  \n",
       "4  Chapter 18. Context Managers and else Blocks A...  0.060011        None  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejecuta esta celda para generar el CSV de resultados (sin is_relevant anotado).\n",
    "\n",
    "os.makedirs(EVALS_DIR, exist_ok=True)\n",
    "df_results = build_retrieval_results_dataframe()\n",
    "df_results.to_csv(RETRIEVAL_RESULTS_CSV, index=False)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da513b66",
   "metadata": {},
   "source": [
    "## Cálculo de Precision@5 y nDCG@5\n",
    "\n",
    "Una vez que hayas editado `evals/retrieval_results.csv` y añadido la columna\n",
    "`is_relevant` con valores 0/1, usa las siguientes celdas para calcular\n",
    "las métricas por retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eba1a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(rels: List[int], k: int = 5) -> float:\n",
    "    rels_k = rels[:k]\n",
    "    return sum(rels_k) / float(k) if k > 0 else 0.0\n",
    "\n",
    "def dcg_at_k(rels: List[int], k: int = 5) -> float:\n",
    "    dcg = 0.0\n",
    "    for i, rel in enumerate(rels[:k], start=1):\n",
    "        dcg += rel / math.log2(i + 1)\n",
    "    return dcg\n",
    "\n",
    "def ndcg_at_k(rels: List[int], k: int = 5) -> float:\n",
    "    dcg = dcg_at_k(rels, k)\n",
    "    ideal = sorted(rels, reverse=True)\n",
    "    idcg = dcg_at_k(ideal, k)\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93ea7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotated_results(csv_path: str = RETRIEVAL_RESULTS_CSV) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"is_relevant\" not in df.columns:\n",
    "        raise ValueError(\"El CSV no tiene columna 'is_relevant'. Añádela antes de calcular métricas.\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_per_retriever(df: pd.DataFrame, k: int = 5) -> pd.DataFrame:\n",
    "    # Asegúrate de que is_relevant es 0/1 entero\n",
    "    df[\"is_relevant\"] = df[\"is_relevant\"].fillna(0).astype(int)\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for retriever in df[\"retriever\"].unique():\n",
    "        df_r = df[df[\"retriever\"] == retriever]\n",
    "        p_at_ks = []\n",
    "        ndcg_at_ks = []\n",
    "\n",
    "        for qid in df_r[\"query_id\"].unique():\n",
    "            df_q = df_r[df_r[\"query_id\"] == qid].sort_values(\"rank\")\n",
    "            rels = df_q[\"is_relevant\"].tolist()\n",
    "\n",
    "            p_at_ks.append(precision_at_k(rels, k=k))\n",
    "            ndcg_at_ks.append(ndcg_at_k(rels, k=k))\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"retriever\": retriever,\n",
    "                f\"P@{k}\": sum(p_at_ks) / len(p_at_ks),\n",
    "                f\"nDCG@{k}\": sum(ndcg_at_ks) / len(ndcg_at_ks),\n",
    "                \"num_queries\": len(p_at_ks),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123782f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez anotado el CSV con is_relevant, ejecuta esto:\n",
    "df_annotated = load_annotated_results()\n",
    "metrics_df = compute_metrics_per_retriever(df_annotated, k=5)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0840dc",
   "metadata": {},
   "source": [
    "## Próximos pasos\n",
    "\n",
    "- Añadir un segundo retriever (`dense`) reutilizando tu encoder denso y tu colección híbrida.\n",
    "- Guardar también la información de payload (por ejemplo, título de documento, sección) en el CSV\n",
    "  para facilitar la anotación manual de relevancia.\n",
    "- Probar diferentes valores de `TOP_K` (por ejemplo 3, 10) y comparar métricas.\n",
    "- Integrar este notebook con tus otros notebooks de evaluación de Saucode para tener un flujo\n",
    "  de experimentación completo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
